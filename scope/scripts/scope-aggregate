#!/usr/bin/env python

""" Aggregate sick results into a single file """

from __future__ import division, print_function

__author__ = "Andy Casey <arc@ast.cam.ac.uk>"

import argparse
import json
import logging
import os

import numpy as np
import pyfits

def main():
	""" Aggregate sick results into a single file """

	parser = argparse.ArgumentParser(description="aggregate JSON results into a tabular format")
	parser.add_argument("output_filename", type=str, help="Output filename to aggregate results into")
	parser.add_argument("result_filenames", nargs="+", help="JSON result filenames to combine")
	parser.add_argument("--clobber", action="store", dest="clobber", default=False)
	parser.add_argument("-v", "--verbose", dest="verbose", action="store_true", default=False)
	parser.add_argument("--debug", dest="debug", action="store_true", default=False)
	
	args = parser.parse_args()

	if os.path.exists(args.output_filename) and not args.clobber:
		raise IOError("output filename {0} already exists and we have been asked not to clobber it".format(args.output_filename))

	# Initialise logging
	logging.basicConfig(level=logging.DEBUG if args.verbose else logging.INFO)
	logger = logging.getLogger("sick")
	
	# Let's just assume it all aggregates from JSON to a FITS filename
	results = []
	for filename in args.result_filenames:
		with open(filename, "r") as fp:
			try:
				results.append(json.load(fp))
			except:
				if args.debug:
					raise
				logger.warn("Could not read results filename {0}".format(filename))

	# Get header order and sort them
	columns = results[0].keys()

	sorted_columns = []
	# Logic: RA, DEC then all other uppercase fields in alphabetical order
	# Then any other fields that have associated u_* headers in alphabetical order, as well as their u_* columns
	# Then all the others in alphabetical order
	if "RA" in columns:
		sorted_columns.append("RA")

	if "DEC" in columns:
		sorted_columns.append("DEC")

	uppercase_columns = []
	dimensional_columns = []
	for column in columns:
		if column.isupper() and column not in sorted_columns: uppercase_columns.append(column)
		elif "u_pos_{0}".format(column) in columns: dimensional_columns.append(column)

	
	uppercase_columns, dimensional_columns = map(sorted, [uppercase_columns, dimensional_columns])
	all_dimensional_columns = []
	variants = ("{0}", "u_pos_{0}", "u_neg_{0}", "u_maxabs_{0}")
	for column in dimensional_columns:
		all_dimensional_columns.extend([variant.format(column) for variant in variants])

	sorted_columns.extend(uppercase_columns)
	sorted_columns.extend(all_dimensional_columns)

	other_columns = sorted(set(columns).difference(sorted_columns))
	sorted_columns.extend(list(other_columns))

	# Create data types
	formats = [("f8", "|S256")[isinstance(results[0][each], str)] for each in sorted_columns]

	# Create table
	results_table = np.core.records.fromrecords(
		[[result.get(each, ["|S256", np.nan][formats[i] == "f8"]) for i, each in enumerate(sorted_columns)] for result in results],
		names=sorted_columns, formats=formats)

	# Write results to filename	
	primary_hdu = pyfits.PrimaryHDU()
	table_hdu = pyfits.BinTableHDU(results_table)
	hdulist = pyfits.HDUList([primary_hdu, table_hdu])
	hdulist.writeto(args.output_filename, clobber=args.clobber)

	logger.info("Successfully written {0} results with {1} fields to {2}".format(
		len(results), len(results[0]), args.output_filename))

if __name__ == "__main__":
	main()
