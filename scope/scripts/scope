#!/usr/bin/python

""" Script to run SCOPE from the command line """

from __future__ import division, print_function

__author__ = "Andy Casey <arc@ast.cam.ac.uk>"

import argparse
import logging
import os
import cPickle as pickle

from hashlib import md5
from json import dumps as json_dumps
from time import time

import numpy as np
import pyfits

import scope

def main():

	parser = argparse.ArgumentParser(description="infer stellar parameters from spectra")
	parser.add_argument("model", type=str, help="YAML- or JSON-style model filename")
	parser.add_argument("spectra", nargs="+", help="filenames of spectra to analyse")
	parser.add_argument("-o", "--output-dir", dest="output_dir", nargs="?", help="directory for output files",
		type=str, default=os.getcwd())
	parser.add_argument("--no-plots", dest="plotting", action="store_false", default=True)
	parser.add_argument("-v", "--verbose", dest="verbose", action="store_true", default=False)
	parser.add_argument("--debug", dest="debug", action="store_true", default=False)

	args = parser.parse_args()
	logger = logging.basicConfig(level=logging.DEBUG if (args.debug or args.verbose) else logging.INFO)

	if not os.path.exists(args.model):
		raise IOError("model filename does not exist")

	all_spectra = [scope.Spectrum.load(filename) for filename in args.spectra]

	if args.plotting:
		# Import plotting dependencies 
		import matplotlib.pyplot as plt
		import triangle

	# Are there multiple spectra in each aperture?
	if isinstance(all_spectra[0], list):
		# If so, they should all have the same length (e.g. same number of stars)
		if len(set(map(len, all_spectra))) > 1:
			raise IOError("filenames contain different number of spectra")

		# OK, they have the same length. They are probably apertures of the same
		# stars. Let's join them properly
		sorted_spectra = []
		num_stars, num_apertures = len(all_spectra[0]), len(all_spectra)
		for i in xrange(num_stars):
			sorted_spectra.append([all_spectra[j][i] for j in xrange(num_apertures)])

		all_spectra = sorted_spectra

	else:
		all_spectra = [all_spectra]

	# Define headers that we want in the results filename 
	default_headers = ("RA", "DEC", "COMMENT", "ELAPSED", "FIBRE_NUM", "LAT_OBS", "LONG_OBS",
		"MAGNITUDE","NAME", "OBJECT", "RO_GAIN", "RO_NOISE", "UTDATE", "UTEND", "UTSTART", )
	default_metadata = {
		"model": "",
		"filenames": ", ".join(args.spectra)
	}

	# For each spectra, analyse
	for i, spectra in enumerate(all_spectra):

		# Create metadata and put header information in
		metadata = {}
		bluest_spectrum = spectra[0] if isinstance(spectra, list) else spectra
		for header in default_headers:
			if header not in bluest_spectrum.headers: continue
			metadata[header] = bluest_spectrum.headers[header]

		# Set defaults for metadata
		metadata.update(default_metadata)

		try:
			t_init = time()
			posteriors, sampler, model, mean_acceptance_fractions = scope.solve(spectra, args.model)

		except:
			logger.exception("Failed to analyse #{0}:".format(i))

			if args.debug:
				raise
			
			# Update the metadata with the model information, as well as NaN's for posteriors
			metadata.update({
				"model": md5(json_dumps(model.configuration).encode("utf-8")).hexdigest(),
				"time_elapsed": time() - t_init
			})
			for dimension in model.dimensions:
				metadata[dimension] = np.nan
				metadata["u_maxabs_{0}".format(dimension)] = np.nan
				metadata["u_pos{0}".format(dimension)] = np.nan
				metadata["u_neg_{0}".format(dimension)] = np.nan

		else:
			# Save information related to the analysis
			metadata.update({
				"model": md5(json_dumps(model.configuration).encode("utf-8")).hexdigest(),
				"time_elapsed": int(time() - t_init)
			})

			# Update results with the posteriors
			for dimension, (posterior_value, pos_uncertainty, neg_uncertainty) in posteriors.iteritems():
				metadata.update({
					dimension: posterior_value,
					"u_maxabs_{0}".format(dimension): np.abs([neg_uncertainty, pos_uncertainty]).max(),
					"u_pos_{0}".format(dimension): pos_uncertainty,
					"u_neg_{0}".format(dimension): neg_uncertainty
				})

			# Save the sampler chain
			blobs = np.array(sampler.blobs)
			blobs = blobs.reshape((-1, 1 + len(model.dimensions)))
			chain = np.core.records.fromarrays(blobs.T,
				names=model.dimensions + ["ln L"],
				formats=["f8"] * (1 + len(model.dimensions)))

			filename_prefix = "scope-{0}".format(i)

			with open(os.path.join(args.output_dir, filename_prefix + ".chain"), "wb") as fp:
				pickle.dump(chain, fp)

			with open(os.path.join(args.output_dir, filename_prefix + ".results"), "wb") as fp:
				pickle.dump((posteriors, mean_acceptance_fractions), fp)

			# Plot results
			if args.plotting:

				# Make a corner plot
				fig = plt.figure()
				ax = fig.add_subplot(111)
				ax.plot(acceptance_fractions)
				ax.set_xlabel("Iterations")
				ax.set_ylabel("$\langle{}f_a\rangle$")
				fig.savefig(filename_prefix + "-acceptance.pdf")

				ndim = sampler.chain.shape[-1]
				fig = triangle.corner(sampler.chain.reshape((-1, ndim))[-int(model.configuration["solver"]["nwalkers"] * model.configuration["solver"]["sample"] * 0.5):, :],
					labels=scope.utils.latexify(model.dimensions))
				fig.savefig(filename_prefix + "-corner.pdf")

				# Get the most probable spectra
				me_index = np.argmax(chain[:, -1])
				me_parameters = dict(zip(model.dimensions, chain[me_index, :-1]))

				me_observed_spectra = model.observed_spectra(spectra, **me_parameters)
				me_model_spectra = model.model_spectra(observations=me_observed_spectra, **me_parameters)

				fig = plt.figure()
				for i, (aperture, observed_aperture) in enumerate(zip(model._mapped_apertures, me_observed_spectra)):

					ax = fig.add_subplot(len(spectra), 1, i+1)

					modelled_aperture = me_model_spectra[aperture]
					ax.plot(modelled_aperture.disp, modelled_aperture.flux, 'b')
					ax.plot(observed_aperture.disp, observed_aperture.flux, 'k')

					# Get the full boundaries
					if "masks" in model.configuration and aperture in model.configuration["masks"]:
						full_extent = \
							(np.min(model.configuration["masks"][aperture]), np.max(model.configuration["masks"][aperture]))

						ax.set_xlim(full_extent)

					ax.set_ylim(0.6, 1.2)

				fig.savefig(filename_prefix + "-spectra.pdf")

				# Closing the figures isn't enough; matplotlib leaks memory
				plt.close("all")


		# Save the metadata to the results list
		if i == 0:
			metadata_columns = metadata.keys()
			metadata_formats = [("f8", "|S1024")[isinstance(str, value)] for value in metadata.values()]
			all_results = np.core.records.fromrecords([metadata.values()],
				names=metadata.keys(), formats=metadata_formats)

		else:
			all_results = np.append(all_results, np.array([(metadata[key] for key in metadata_columns)],
				dtype=all_results.dtype))

		hdu = pyfits.PrimaryHDU(results_array)
		hdulist = pyfits.HDUList([hdu])
		hdulist.writeto(os.path.join(output_dir, "scope-results.fits"), clobber=True)

		# Save all results thus far to a fits file	
		if i >= 1:
			raise NotImplementedError

if __name__ == "__main__":
	main()